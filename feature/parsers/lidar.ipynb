{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:19:45.109976500Z",
     "start_time": "2023-12-23T19:19:42.434684300Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "import geopandas as gpd\n",
    "import laspy\n",
    "import numpy as np\n",
    "import startinpy\n",
    "\n",
    "import raster\n",
    "from feature.utils import timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class PointCloud:\n",
    "    @timing\n",
    "    def __init__(self, filename: str) -> None:\n",
    "        with laspy.open(filename) as f:\n",
    "            self.las = f.read()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.las.points)\n",
    "\n",
    "    def __getitem__(self, key: int):\n",
    "        ...\n",
    "\n",
    "\n",
    "# FIXME: Rewrite this function as a PointCloud method.\n",
    "@timing\n",
    "def to_gdf(pc: PointCloud) -> gpd.GeoDataFrame:\n",
    "    return gpd.GeoDataFrame({\"id\": np.arange(len(pc)), \"geometry\": gpd.points_from_xy(pc.las.x, pc.las.y)},\n",
    "                            crs=\"EPSG:28992\")\n",
    "\n",
    "\n",
    "# FIXME: Rewrite this function as a PointCloud method.\n",
    "@timing\n",
    "def intersect(pc: PointCloud, objs: gpd.GeoDataFrame) -> np.ndarray:\n",
    "    return to_gdf(pc).overlay(objs)[\"id_1\"].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:19:46.209555100Z",
     "start_time": "2023-12-23T19:19:46.201772900Z"
    }
   },
   "id": "548a90cb376094fb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# class BufferableGeoDataFrame(gpd.GeoDataFrame):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super().__init__()\n",
    "# \n",
    "#     def buffer(self, *args, **kwargs) -> None:\n",
    "#         ...\n",
    "\n",
    "@timing\n",
    "def __init__(filename: str) -> gpd.GeoDataFrame:\n",
    "    return gpd.read_file(filename)\n",
    "\n",
    "\n",
    "@timing\n",
    "# TODO: Review the various buffer options.\n",
    "# TODO: Rewrite this function as an appropriate class method.\n",
    "def buffer(objs: gpd.GeoDataFrame, dist: float = 10) -> None:\n",
    "    objs[\"geometry\"] = objs[\"geometry\"].buffer(dist)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:19:48.238966500Z",
     "start_time": "2023-12-23T19:19:48.224452900Z"
    }
   },
   "id": "7840663c63c1bac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1\n",
    "Load the point cloud into memory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e916cbd201c518a8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func __init__ :-> 355 ms\n"
     ]
    }
   ],
   "source": [
    "pc = PointCloud(\"../aula.LAZ\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:19:50.701796100Z",
     "start_time": "2023-12-23T19:19:50.342771Z"
    }
   },
   "id": "5eb5b746d283a153"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2\n",
    "Load the building footprints into memory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7fe307e154c1d3c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func __init__ :-> 745 ms\n"
     ]
    }
   ],
   "source": [
    "fps = __init__(\"C:/Documents/RoofSense/data/temp/9-284-556.buildings.gpkg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:19:52.695433200Z",
     "start_time": "2023-12-23T19:19:51.947867500Z"
    }
   },
   "id": "364ede887fa959cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3\n",
    "Buffer the footprints by 10 m.\n",
    "\n",
    "NOTE: The buffer distance is selected such that most if not all the natural neighbors of \n",
    "      the points along the footprint edges are included in the subsequent steps."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79d54e36b38a0e7b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func buffer :-> 111 ms\n"
     ]
    }
   ],
   "source": [
    "buffer(fps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:19:54.202769100Z",
     "start_time": "2023-12-23T19:19:54.057760200Z"
    }
   },
   "id": "f06ed91f3932d9a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4\n",
    "Intersect the point cloud with the buffers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3182f01a5065379d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func to_gdf :-> 2479 ms\n",
      "func intersect :-> 32753 ms\n"
     ]
    }
   ],
   "source": [
    "ids = intersect(pc, fps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:20:28.690703700Z",
     "start_time": "2023-12-23T19:19:55.935162200Z"
    }
   },
   "id": "c6d4240eb0d1a706"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter the point cloud and detach the point records which are required in the subsequent\n",
    "steps."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8549980f9dc4935"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# TOSELF: Overwrite the original point cloud?\n",
    "pts = pc.las.points[ids]\n",
    "pts = np.vstack((pts.x, pts.y, \n",
    "                 # NOTE: The point elevation must be used instead of e.g., reflectance\n",
    "                 #       because it is required in the subsequent steps.\n",
    "                 pts.z)).transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:20:28.953858600Z",
     "start_time": "2023-12-23T19:20:28.690703700Z"
    }
   },
   "id": "c8df46c48eb0d8b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5\n",
    "Compute the Delaunay triangulation of the remaining points."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ebb7d620ce6ce9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# FIXME: Rewrite this block as a PointCloud method and improve its documentation.\n",
    "\n",
    "dt = startinpy.DT()\n",
    "# NOTE: The snap tolerance cannot be set to zero (i.e., disabled) so the nearest \n",
    "#       distinct value is used instead.\n",
    "dt.snap_tolerance = math.ulp(0)\n",
    "\n",
    "# Maintain a reference to the duplicate PC vertices.\n",
    "# NOTE: Two or more vertices are considered to be duplicate when their two-dimensional \n",
    "#       projections on the Euclidean plane are identical. However. they can obviously \n",
    "#       differ in n-dimensional space. In this context these vertices are rechecked \n",
    "#       after the DT has been constructed so that the one with the highest elevation is \n",
    "#       actually inserted.\n",
    "tentative_pts: dict[int,  # NOTE: There may be more than one duplicate points.\n",
    "list[int]] = collections.defaultdict(list)\n",
    "# Maintain a reference to the finalized PC vertices.\n",
    "finalized_pts: dict[int, int] = {}\n",
    "\n",
    "candidate_id: int  # The ID of a candidate vertex in the PC.\n",
    "tentative_id: int  # The ID of a candidate vertex in the DT.\n",
    "finalized_id: int  # The ID of a candidate vertex in the DT.\n",
    "\n",
    "tentative_id = 1\n",
    "for candidate_id, pt in enumerate(pts):\n",
    "    finalized_id = dt.insert_one_pt(*pt)\n",
    "    if finalized_id == tentative_id:\n",
    "        finalized_pts[finalized_id] = candidate_id\n",
    "        tentative_id += 1\n",
    "    else:\n",
    "        tentative_pts[finalized_id].append(candidate_id)\n",
    "\n",
    "# NOTE: This array is compiled on demand.\n",
    "dt_pts = dt.points\n",
    "for finalized_id, candidate_ids in tentative_pts.items():\n",
    "    for candidate_id in candidate_ids:\n",
    "        if dt_pts[finalized_id][2] > pts[candidate_id][2]:\n",
    "            dt.remove(finalized_id)\n",
    "            dt.insert_one_pt(*pts[candidate_id])\n",
    "            # Replace the previous ID of the vertex in the PC with the current one.\n",
    "            finalized_pts[finalized_id] = candidate_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:20:58.754394700Z",
     "start_time": "2023-12-23T19:20:50.000633700Z"
    }
   },
   "id": "6000a96d7322459c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confirm that the resulting lookup table is correct."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e938773e3170f26"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(dt.points[1:], pts[list(finalized_pts.values())])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:21:40.164181300Z",
     "start_time": "2023-12-23T19:21:39.977423200Z"
    }
   },
   "id": "567611dc1bd9ebd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6\n",
    " Estimate the slope field of the corresponding network.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1acda9b25193f2fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2aef8440222114"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# TOSELF: Promote this argument to an environment variable?\n",
    "CELL_SIZE = 0.25\n",
    "\n",
    "grid = raster.Raster(CELL_SIZE, dt.get_bbox())\n",
    "\n",
    "# FIXME: Integrate this block into the Raster initializer.\n",
    "# Construct the grid.\n",
    "# TODO: Add documentation.\n",
    "rows, cols = np.mgrid[grid.len_y - 1:-1:-1, 0:grid.len_x]\n",
    "# TODO: Add documentation.\n",
    "xx = grid.bbox[0] + CELL_SIZE * (cols + 0.5)\n",
    "yy = grid.bbox[1] + CELL_SIZE * (rows + 0.5)\n",
    "# TODO: Add documentation.\n",
    "cells = np.column_stack([xx.ravel(), yy.ravel()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:40:43.217625300Z",
     "start_time": "2023-12-23T19:40:43.130444900Z"
    }
   },
   "id": "ed9854112d57cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c1d49d95552f2f4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# TODO: Speed up this block.\n",
    "# TOSELF: Compute the slope for all faces to avoid additional calls to dt.locate?\n",
    "valid_cells = []\n",
    "valid_faces = []\n",
    "for i, center in enumerate(cells):\n",
    "    try:\n",
    "        valid_faces.append(dt.locate(*center))\n",
    "    except Exception:\n",
    "        continue\n",
    "    valid_cells.append(i)\n",
    "\n",
    "# TOSELF: Discard duplicate faces?\n",
    "# valid_faces = np.unique(valid_faces, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:43:11.645988900Z",
     "start_time": "2023-12-23T19:40:47.903999100Z"
    }
   },
   "id": "2a4ab4ba6f8d5053"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# TODO: Add documentation.\n",
    "\n",
    "valid_faces = np.array(valid_faces)\n",
    "v1 = dt_pts[valid_faces[:, 0]]\n",
    "v2 = dt_pts[valid_faces[:, 1]]\n",
    "v3 = dt_pts[valid_faces[:, 2]]\n",
    "\n",
    "u = v2 - v1\n",
    "v = v3 - v1\n",
    "\n",
    "n = np.cross(u, v)\n",
    "n = n / np.linalg.norm(n, axis=1)[:, None]\n",
    "\n",
    "z = np.array([0, 0, 1])\n",
    "s = np.degrees(np.arccos(np.dot(n, z)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:45:23.818092600Z",
     "start_time": "2023-12-23T19:45:23.384177800Z"
    }
   },
   "id": "d1ba336a8b385c07"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "grid._Raster__data[np.divmod(valid_cells, grid.len_x)] = s\n",
    "grid.save(\"../aula_slpe.tiff\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:45:26.984939100Z",
     "start_time": "2023-12-23T19:45:26.725907700Z"
    }
   },
   "id": "4ae0726e50840615"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6\n",
    " Rasterize the slope and reflectance fields of the corresponding network."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e185553d6a7ec93f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "Deleting ../aula_elev.tiff failed: Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCPLE_AppDefinedError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m grid\u001B[38;5;241m.\u001B[39m_Raster__data \u001B[38;5;241m=\u001B[39m vals\u001B[38;5;241m.\u001B[39mreshape((grid\u001B[38;5;241m.\u001B[39mlen_y, grid\u001B[38;5;241m.\u001B[39mlen_x))\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Save the raster.\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../aula_elev.tiff\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Documents\\RoofSense\\feature\\parsers\\raster.py:70\u001B[0m, in \u001B[0;36mRaster.save\u001B[1;34m(self, filename)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Define an appropriate transformation to map the position of each cell from raster space to real-world\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;66;03m# coordinates.\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# noinspection PyUnresolvedReferences\u001B[39;00m\n\u001B[0;32m     66\u001B[0m ij_to_xy \u001B[38;5;241m=\u001B[39m rasterio\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mfrom_origin(\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbbox[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbbox[\u001B[38;5;241m3\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cell_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cell_size\n\u001B[0;32m     68\u001B[0m )\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mrasterio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlen_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlen_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mij_to_xy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     78\u001B[0m     f\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__data, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mC:\\Documents\\RoofSense\\venv\\Lib\\site-packages\\rasterio\\env.py:451\u001B[0m, in \u001B[0;36mensure_env_with_credentials.<locals>.wrapper\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    448\u001B[0m     session \u001B[38;5;241m=\u001B[39m DummySession()\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m env_ctor(session\u001B[38;5;241m=\u001B[39msession):\n\u001B[1;32m--> 451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Documents\\RoofSense\\venv\\Lib\\site-packages\\rasterio\\__init__.py:327\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m writer \u001B[38;5;241m=\u001B[39m get_writer_for_driver(driver)\n\u001B[0;32m    326\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 327\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mwriter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdriver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcount\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnodata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnodata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m        \u001B[49m\u001B[43msharing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DriverCapabilityError(\n\u001B[0;32m    343\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWriter does not exist for driver: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mstr\u001B[39m(driver)\n\u001B[0;32m    344\u001B[0m     )\n",
      "File \u001B[1;32mrasterio\\\\_io.pyx:1464\u001B[0m, in \u001B[0;36mrasterio._io.DatasetWriterBase.__init__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mrasterio\\\\_io.pyx:330\u001B[0m, in \u001B[0;36mrasterio._io._delete_dataset_if_exists\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mrasterio\\\\_err.pyx:195\u001B[0m, in \u001B[0;36mrasterio._err.exc_wrap_int\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mCPLE_AppDefinedError\u001B[0m: Deleting ../aula_elev.tiff failed: Permission denied"
     ]
    }
   ],
   "source": [
    "# Interpolate the field values at the cell centers.\n",
    "vals = dt.interpolate({\"method\": \"Laplace\"}, cells)\n",
    "\n",
    "# Populate the raster.\n",
    "grid._Raster__data = vals.reshape((grid.len_y, grid.len_x))\n",
    "\n",
    "# Save the raster.\n",
    "grid.save(\"../aula_elev.tiff\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:47:38.005620400Z",
     "start_time": "2023-12-23T19:45:47.133508500Z"
    }
   },
   "id": "87674224aafa3e61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
