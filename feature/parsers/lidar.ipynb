{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:44:27.805695Z",
     "start_time": "2023-12-28T18:44:27.796228700Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "from typing import Sequence\n",
    "\n",
    "import geopandas as gpd\n",
    "import laspy\n",
    "import numpy as np\n",
    "import startinpy\n",
    "\n",
    "import raster\n",
    "from feature.utils import timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "class PointCloud:\n",
    "    @timing\n",
    "    def __init__(self, filename: str) -> None:\n",
    "        with laspy.open(filename) as f:\n",
    "            self.las = f.read()\n",
    "\n",
    "    @timing\n",
    "    def crop(self, bbox: Sequence[float]) -> PointCloud:\n",
    "        min_x = (bbox[0] - self.las.header.x_offset) / self.las.header.x_scale\n",
    "        min_y = (bbox[1] - self.las.header.y_offset) / self.las.header.y_scale\n",
    "        max_x = (bbox[2] - self.las.header.x_offset) / self.las.header.x_scale\n",
    "        max_y = (bbox[3] - self.las.header.y_offset) / self.las.header.y_scale\n",
    "        self.las.points = self.las.points[np.logical_and(np.logical_and(min_x <= self.las.X, self.las.X <= max_x),\n",
    "                                                         np.logical_and(min_y <= self.las.Y, self.las.Y <= max_y))]\n",
    "        return self\n",
    "\n",
    "    def save(self, filename: str) -> None:\n",
    "        with laspy.open(filename, \"w\", header=self.las.header, do_compress=True) as f:\n",
    "            f.write_points(self.las.points)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.las.points)\n",
    "\n",
    "    def __getitem__(self, key: int):\n",
    "        ...\n",
    "\n",
    "\n",
    "# FIXME: Rewrite this function as a PointCloud method.\n",
    "@timing\n",
    "def to_gdf(pc: PointCloud) -> gpd.GeoDataFrame:\n",
    "    return gpd.GeoDataFrame({\"id\": np.arange(len(pc)), \"geometry\": gpd.points_from_xy(pc.las.x, pc.las.y)},\n",
    "                            crs=\"EPSG:28992\")\n",
    "\n",
    "\n",
    "# FIXME: Rewrite this function as a PointCloud method.\n",
    "@timing\n",
    "def intersect(pc: PointCloud, objs: gpd.GeoDataFrame) -> np.ndarray:\n",
    "    return to_gdf(pc).overlay(objs)[\"id_1\"].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:23:49.848715800Z",
     "start_time": "2023-12-28T19:23:49.829933Z"
    }
   },
   "id": "548a90cb376094fb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func __init__ :-> 3154 ms\n",
      "<ScaleAwarePointRecord(fmt: <PointFormat(8, 6 bytes of extra dims)>, len: 50334569, point size: 44)>\n",
      "func crop :-> 1429 ms\n"
     ]
    }
   ],
   "source": [
    "pc = PointCloud(\"C:/Documents/RoofSense/data/temp/37EN2_16.LAZ\")\n",
    "print(pc.las.points)\n",
    "pc.crop([84489.9256187045539264, 445795.0548930063378066, 85685.1996997416717932, 446993.4567845478304662]).save(\n",
    "    '37EN2_16.LAZ_crop.laz')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:25:15.302844600Z",
     "start_time": "2023-12-28T19:25:09.770654300Z"
    }
   },
   "id": "fa82e11715d12077",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# class BufferableGeoDataFrame(gpd.GeoDataFrame):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super().__init__()\n",
    "# \n",
    "#     def buffer(self, *args, **kwargs) -> None:\n",
    "#         ...\n",
    "\n",
    "@timing\n",
    "def __init__(filename: str) -> gpd.GeoDataFrame:\n",
    "    return gpd.read_file(filename)\n",
    "\n",
    "\n",
    "@timing\n",
    "# TODO: Review the various buffer options.\n",
    "# TODO: Rewrite this function as an appropriate class method.\n",
    "def buffer(objs: gpd.GeoDataFrame, dist: float = 10) -> None:\n",
    "    objs[\"geometry\"] = objs[\"geometry\"].buffer(dist)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:10:18.560848400Z",
     "start_time": "2023-12-25T22:10:18.549547600Z"
    }
   },
   "id": "7840663c63c1bac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1\n",
    "Load the point cloud into memory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e916cbd201c518a8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func __init__ :-> 289 ms\n"
     ]
    }
   ],
   "source": [
    "pc = PointCloud(\"../aula.LAZ\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:10:18.849086800Z",
     "start_time": "2023-12-25T22:10:18.555851100Z"
    }
   },
   "id": "5eb5b746d283a153"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2\n",
    "Load the building footprints into memory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7fe307e154c1d3c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func __init__ :-> 774 ms\n"
     ]
    }
   ],
   "source": [
    "fps = __init__(\"C:/Documents/RoofSense/data/temp/9-284-556.buildings.gpkg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:10:19.628853100Z",
     "start_time": "2023-12-25T22:10:18.850087900Z"
    }
   },
   "id": "364ede887fa959cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3\n",
    "Buffer the footprints by 10 m.\n",
    "\n",
    "NOTE: The buffer distance is selected such that most if not all the natural neighbors of \n",
    "      the points along the footprint edges are included in the subsequent steps."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79d54e36b38a0e7b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func buffer :-> 74 ms\n"
     ]
    }
   ],
   "source": [
    "buffer(fps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:10:19.709369500Z",
     "start_time": "2023-12-25T22:10:19.628853100Z"
    }
   },
   "id": "f06ed91f3932d9a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4\n",
    "Intersect the point cloud with the buffers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3182f01a5065379d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func to_gdf :-> 2318 ms\n",
      "func intersect :-> 32190 ms\n"
     ]
    }
   ],
   "source": [
    "ids = intersect(pc, fps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:10:51.901838600Z",
     "start_time": "2023-12-25T22:10:19.707375Z"
    }
   },
   "id": "c6d4240eb0d1a706"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter the point cloud and detach the point records which are required in the subsequent\n",
    "steps."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8549980f9dc4935"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# TOSELF: Overwrite the original point cloud?\n",
    "pts = pc.las.points[ids]\n",
    "pts = np.vstack((pts.x, pts.y,  # NOTE: The point elevation must be used instead of e.g., reflectance\n",
    "                 #       because it is required in the subsequent steps.\n",
    "                 pts.z)).transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:10:52.182804500Z",
     "start_time": "2023-12-25T22:10:51.901838600Z"
    }
   },
   "id": "c8df46c48eb0d8b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5\n",
    "Compute the Delaunay triangulation of the remaining points."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ebb7d620ce6ce9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# FIXME: Rewrite this block as a PointCloud method and improve its documentation.\n",
    "\n",
    "dt = startinpy.DT()\n",
    "# NOTE: The snap tolerance cannot be set to zero (i.e., disabled) so the nearest \n",
    "#       distinct value is used instead.\n",
    "dt.snap_tolerance = math.ulp(0)\n",
    "\n",
    "# Maintain a reference to the duplicate PC vertices.\n",
    "# NOTE: Two or more vertices are considered to be duplicate when their two-dimensional \n",
    "#       projections on the Euclidean plane are identical. However. they can obviously \n",
    "#       differ in n-dimensional space. In this context these vertices are rechecked \n",
    "#       after the DT has been constructed so that the one with the highest elevation is \n",
    "#       actually inserted.\n",
    "tentative_pts: dict[int,  # NOTE: There may be more than one duplicate points.\n",
    "list[int]] = collections.defaultdict(list)\n",
    "# Maintain a reference to the finalized PC vertices.\n",
    "finalized_pts: dict[int, int] = {}\n",
    "\n",
    "candidate_id: int  # The ID of a candidate vertex in the PC.\n",
    "tentative_id: int  # The ID of a candidate vertex in the DT.\n",
    "finalized_id: int  # The ID of a candidate vertex in the DT.\n",
    "\n",
    "tentative_id = 1\n",
    "for candidate_id, pt in enumerate(pts):\n",
    "    finalized_id = dt.insert_one_pt(*pt)\n",
    "    if finalized_id == tentative_id:\n",
    "        finalized_pts[finalized_id] = candidate_id\n",
    "        tentative_id += 1\n",
    "    else:\n",
    "        tentative_pts[finalized_id].append(candidate_id)\n",
    "\n",
    "# NOTE: This array is compiled on demand.\n",
    "dt_pts = dt.points\n",
    "for finalized_id, candidate_ids in tentative_pts.items():\n",
    "    for candidate_id in candidate_ids:\n",
    "        if dt_pts[finalized_id][2] > pts[candidate_id][2]:\n",
    "            dt.remove(finalized_id)\n",
    "            dt.insert_one_pt(*pts[candidate_id])\n",
    "            # Replace the previous ID of the vertex in the PC with the current one.\n",
    "            finalized_pts[finalized_id] = candidate_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:11:00.907919900Z",
     "start_time": "2023-12-25T22:10:52.184797Z"
    }
   },
   "id": "6000a96d7322459c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confirm that the resulting lookup table is correct."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e938773e3170f26"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(dt.points[1:], pts[list(finalized_pts.values())])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:11:01.227687300Z",
     "start_time": "2023-12-25T22:11:00.908921900Z"
    }
   },
   "id": "567611dc1bd9ebd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6\n",
    " Estimate the slope field of the corresponding network.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1acda9b25193f2fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2aef8440222114"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# TOSELF: Promote this argument to an environment variable?\n",
    "CELL_SIZE = 0.25\n",
    "\n",
    "grid = raster.Raster(CELL_SIZE, dt.get_bbox())\n",
    "\n",
    "# FIXME: Integrate this block into the Raster initializer.\n",
    "# Construct the grid.\n",
    "# TODO: Add documentation.\n",
    "rows, cols = np.mgrid[grid.len_y - 1:-1:-1, 0:grid.len_x]\n",
    "# TODO: Add documentation.\n",
    "xx = grid.bbox[0] + CELL_SIZE * (cols + 0.5)\n",
    "yy = grid.bbox[1] + CELL_SIZE * (rows + 0.5)\n",
    "# TODO: Add documentation.\n",
    "cells = np.column_stack([xx.ravel(), yy.ravel()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:11:01.295420900Z",
     "start_time": "2023-12-25T22:11:01.224685400Z"
    }
   },
   "id": "ed9854112d57cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c1d49d95552f2f4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# TODO: Speed up this block.\n",
    "# TOSELF: Compute the slope for all faces to avoid additional calls to dt.locate?\n",
    "valid_cells = []\n",
    "valid_faces = []\n",
    "for i, center in enumerate(cells):\n",
    "    try:\n",
    "        valid_faces.append(dt.locate(*center))\n",
    "    except Exception:\n",
    "        continue\n",
    "    valid_cells.append(i)\n",
    "\n",
    "# TOSELF: Discard duplicate faces?\n",
    "# valid_faces = np.unique(valid_faces, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:13:14.078383100Z",
     "start_time": "2023-12-25T22:11:01.281417900Z"
    }
   },
   "id": "2a4ab4ba6f8d5053"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# TODO: Add documentation.\n",
    "\n",
    "valid_faces = np.array(valid_faces)\n",
    "v1 = dt_pts[valid_faces[:, 0]]\n",
    "v2 = dt_pts[valid_faces[:, 1]]\n",
    "v3 = dt_pts[valid_faces[:, 2]]\n",
    "\n",
    "u = v2 - v1\n",
    "v = v3 - v1\n",
    "\n",
    "n = np.cross(u, v)\n",
    "n = n / np.linalg.norm(n, axis=1)[:, None]\n",
    "\n",
    "z = np.array([0, 0, 1])\n",
    "s = np.degrees(np.arccos(np.dot(n, z)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:13:15.581471800Z",
     "start_time": "2023-12-25T22:13:14.078383100Z"
    }
   },
   "id": "d1ba336a8b385c07"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "grid._Raster__data[np.divmod(valid_cells, grid.len_x)] = s\n",
    "grid.save(\"../aula_slpe.tiff\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:13:15.916006Z",
     "start_time": "2023-12-25T22:13:15.563474800Z"
    }
   },
   "id": "4ae0726e50840615"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6\n",
    " Rasterize the slope and reflectance fields of the corresponding network."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e185553d6a7ec93f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Interpolate the field values at the cell centers.\n",
    "vals = dt.interpolate({\"method\": \"Laplace\"}, cells)\n",
    "\n",
    "# Populate the raster.\n",
    "grid._Raster__data = vals.reshape((grid.len_y, grid.len_x))\n",
    "\n",
    "# Save the raster.\n",
    "grid.save(\"../aula_elev.tiff\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:15:15.333567400Z",
     "start_time": "2023-12-25T22:13:15.917006Z"
    }
   },
   "id": "87674224aafa3e61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
