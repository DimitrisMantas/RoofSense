{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5b65df",
   "metadata": {},
   "source": [
    "# LEVIR-CD+ change detection example notebook\n",
    "\n",
    "We start off by installing torchgeo. If you are running this on Colab, then you will need to restart your runtime after this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4627b902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:51.897885200Z",
     "start_time": "2024-02-06T22:03:32.340142500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchgeo in c:\\documents\\roofsense\\venv\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: einops>=0.3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (0.7.0)\n",
      "Requirement already satisfied: fiona>=1.8.19 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (1.9.5)\n",
      "Requirement already satisfied: kornia>=0.6.9 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (0.7.1)\n",
      "Requirement already satisfied: lightly>=1.4.4 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (1.4.24)\n",
      "Requirement already satisfied: lightning[pytorch-extra]>=2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.1.3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (2.1.3)\n",
      "Requirement already satisfied: pillow>=8 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (10.1.0)\n",
      "Requirement already satisfied: pyproj>=3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (3.6.1)\n",
      "Requirement already satisfied: rasterio>=1.2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (1.3.9)\n",
      "Requirement already satisfied: rtree>=1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (1.1.0)\n",
      "Requirement already satisfied: segmentation-models-pytorch>=0.2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (0.3.3)\n",
      "Requirement already satisfied: shapely>=1.7.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (2.0.2)\n",
      "Requirement already satisfied: timm>=0.4.12 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (0.9.2)\n",
      "Requirement already satisfied: torch>=1.12 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (2.1.1+cu118)\n",
      "Requirement already satisfied: torchmetrics>=0.10 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (1.2.1)\n",
      "Requirement already satisfied: torchvision>=0.13 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torchgeo) (0.16.1+cu118)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (23.1.0)\n",
      "Requirement already satisfied: certifi in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (0.7.2)\n",
      "Requirement already satisfied: six in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fiona>=1.8.19->torchgeo) (68.2.0)\n",
      "Requirement already satisfied: packaging in c:\\documents\\roofsense\\venv\\lib\\site-packages (from kornia>=0.6.9->torchgeo) (23.2)\n",
      "Requirement already satisfied: hydra-core>=1.0.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (1.3.2)\n",
      "Requirement already satisfied: lightly-utils~=0.0.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (0.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.44 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (4.66.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (2.1.0)\n",
      "Requirement already satisfied: pydantic<2,>=1.10.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (1.10.13)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (3.1.15)\n",
      "Requirement already satisfied: pytorch-lightning>=1.0.4 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightly>=1.4.4->torchgeo) (2.1.3)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (2023.4.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (0.10.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (4.9.0)\n",
      "Requirement already satisfied: bitsandbytes<1.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (0.41.3.post2)\n",
      "Requirement already satisfied: jsonargparse[signatures]<5.0,>=4.26.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (4.27.1)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.0.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (2.3.0)\n",
      "Requirement already satisfied: rich<14.0,>=12.3.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (13.7.0)\n",
      "Requirement already satisfied: tensorboardX<3.0,>=2.2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from lightning[pytorch-extra]>=2->torchgeo) (2.6.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from matplotlib>=3.3.3->torchgeo) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from matplotlib>=3.3.3->torchgeo) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from matplotlib>=3.3.3->torchgeo) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from matplotlib>=3.3.3->torchgeo) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from matplotlib>=3.3.3->torchgeo) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from pandas>=1.1.3->torchgeo) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from pandas>=1.1.3->torchgeo) (2023.3)\n",
      "Requirement already satisfied: affine in c:\\documents\\roofsense\\venv\\lib\\site-packages (from rasterio>=1.2->torchgeo) (2.4.0)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from rasterio>=1.2->torchgeo) (1.4.7)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.7.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\documents\\roofsense\\venv\\lib\\site-packages (from timm>=0.4.12->torchgeo) (0.17.3)\n",
      "Requirement already satisfied: safetensors in c:\\documents\\roofsense\\venv\\lib\\site-packages (from timm>=0.4.12->torchgeo) (0.4.1)\n",
      "Requirement already satisfied: munch in c:\\documents\\roofsense\\venv\\lib\\site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch>=0.2->torchgeo) (4.0.0)\n",
      "Requirement already satisfied: filelock in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torch>=1.12->torchgeo) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torch>=1.12->torchgeo) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torch>=1.12->torchgeo) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from torch>=1.12->torchgeo) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\documents\\roofsense\\venv\\lib\\site-packages (from click~=8.0->fiona>=1.8.19->torchgeo) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (3.9.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\documents\\roofsense\\venv\\lib\\site-packages (from hydra-core>=1.0.0->lightly>=1.4.4->torchgeo) (4.9.3)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (0.15)\n",
      "Requirement already satisfied: typeshed-client>=2.1.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests>=2.23.0->lightly>=1.4.4->torchgeo) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests>=2.23.0->lightly>=1.4.4->torchgeo) (3.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (2.17.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]>=2->torchgeo) (4.23.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from jinja2->torch>=1.12->torchgeo) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from sympy->torch>=1.12->torchgeo) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (0.1.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (6.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475f3715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:51.900884800Z",
     "start_time": "2024-02-06T22:03:37.563116Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torchgeo\n",
    "from torchgeo.datasets import LEVIRCDPlus\n",
    "from torchgeo.datasets.utils import unbind_samples\n",
    "from torchgeo.trainers import SemanticSegmentationTask\n",
    "from torchgeo.datamodules.utils import dataset_split\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "from lightning.pytorch import LightningDataModule\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import kornia.augmentation as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae75c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:51.901885600Z",
     "start_time": "2024-02-06T22:03:45.368987100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('0.5.1', '2.1.3', '2.1.1+cu118')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchgeo.__version__, pl.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daedd8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.006443100Z",
     "start_time": "2024-02-06T22:03:51.902885800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b012728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.035442700Z",
     "start_time": "2024-02-06T22:03:51.986228900Z"
    }
   },
   "outputs": [],
   "source": [
    "# some experiment parameters\n",
    "\n",
    "experiment_name = \"experiment_test\"\n",
    "experiment_dir = f\"results/{experiment_name}\"\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 2\n",
    "learning_rate = 0.0001\n",
    "gpu_id = 0\n",
    "device = torch.device(f\"cuda:{gpu_id}\")\n",
    "num_dataloader_workers = 10\n",
    "patch_size = 32\n",
    "val_split_pct = 0.1 # how much of our training set to hold out as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca211445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.084841200Z",
     "start_time": "2024-02-06T22:03:52.035442700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(637, 348)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset and see how many images are in the train and test splits\n",
    "\n",
    "train_dataset = LEVIRCDPlus(root=\"data/LEVIRCDPlus\", split=\"train\")\n",
    "test_dataset = LEVIRCDPlus(root=\"data/LEVIRCDPlus\", split=\"test\")\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e6981",
   "metadata": {},
   "source": [
    "## Excersise 1\n",
    "\n",
    "Plot some examples from the `train_dataset` (note: torchgeo will help you out here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127d129",
   "metadata": {},
   "source": [
    "## Define a PyTorch Lightning module and datamodule\n",
    "\n",
    "PyTorch Lightning organizes the steps required for training deep learning models in `LightningModules`, and organizes the dataset handling to creating dataloaders in `LightningDataModules`. TorchGeo provides pre-built LightningDataModules for a handful of datasets, and pre-built \"trainers\" (i.e. LightningModules) for a variety of different types of tasks.\n",
    "\n",
    "For this tutorial, we will lightly extend TorchGeo's `SemanticSegmentationTask` (just to add some custom plotting code) and create a new LightningDataModule for the LEVIR-CD+ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f62ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.100034900Z",
     "start_time": "2024-02-06T22:03:52.085846200Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSemanticSegmentationTask(SemanticSegmentationTask):\n",
    "    \n",
    "    def plot(self, sample):\n",
    "        image1 = sample[\"image\"][:3]\n",
    "        image2 = sample[\"image\"][3:]\n",
    "        mask = sample[\"mask\"]\n",
    "        prediction = sample[\"prediction\"]\n",
    "\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(4 * 5, 5))\n",
    "        axs[0].imshow(image1.permute(1, 2, 0))\n",
    "        axs[0].axis(\"off\")\n",
    "        axs[1].imshow(image2.permute(1, 2, 0))\n",
    "        axs[1].axis(\"off\")\n",
    "        axs[2].imshow(mask)\n",
    "        axs[2].axis(\"off\")\n",
    "        axs[3].imshow(prediction)\n",
    "        axs[3].axis(\"off\")\n",
    "\n",
    "        axs[0].set_title(\"Image 1\")\n",
    "        axs[1].set_title(\"Image 2\")\n",
    "        axs[2].set_title(\"Mask\")\n",
    "        axs[3].set_title(\"Prediction\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    # The only difference between this code and the same from SemanticSegmentationTask is our redirect to use our own plotting function\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        batch = args[0]\n",
    "        batch_idx = args[1]\n",
    "        \n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        self.train_metrics(y_hat_hard, y)\n",
    "\n",
    "        if batch_idx < 10:\n",
    "            batch[\"prediction\"] = y_hat_hard\n",
    "            for key in [\"image\", \"mask\", \"prediction\"]:\n",
    "                batch[key] = batch[key].cpu()\n",
    "            sample = unbind_samples(batch)[0]\n",
    "            fig = self.plot(sample)\n",
    "            summary_writer = self.logger.experiment\n",
    "            summary_writer.add_figure(\n",
    "                f\"image/train/{batch_idx}\", fig, global_step=self.global_step\n",
    "            )\n",
    "            plt.close()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # The only difference between this code and the same from SemanticSegmentationTask is our redirect to use our own plotting function\n",
    "    def validation_step(self, *args, **kwargs):\n",
    "        batch = args[0]\n",
    "        batch_idx = args[1]\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.val_metrics(y_hat_hard, y)\n",
    "\n",
    "        if batch_idx < 10:\n",
    "            batch[\"prediction\"] = y_hat_hard\n",
    "            for key in [\"image\", \"mask\", \"prediction\"]:\n",
    "                batch[key] = batch[key].cpu()\n",
    "            sample = unbind_samples(batch)[0]\n",
    "            fig = self.plot(sample)\n",
    "            summary_writer = self.logger.experiment\n",
    "            summary_writer.add_figure(\n",
    "                f\"image/val/{batch_idx}\", fig, global_step=self.global_step\n",
    "            )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f420887f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.106326400Z",
     "start_time": "2024-02-06T22:03:52.095336200Z"
    }
   },
   "outputs": [],
   "source": [
    "class LEVIRCDPlusDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        val_split_pct=0.2,\n",
    "        patch_size=(256, 256),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split_pct = val_split_pct\n",
    "        self.patch_size = patch_size\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def on_after_batch_transfer(\n",
    "        self, batch, batch_idx\n",
    "    ):\n",
    "        if (\n",
    "            hasattr(self, \"trainer\")\n",
    "            and self.trainer is not None\n",
    "            and hasattr(self.trainer, \"training\")\n",
    "            and self.trainer.training\n",
    "        ):\n",
    "            # Kornia expects masks to be floats with a channel dimension\n",
    "            x = batch[\"image\"]\n",
    "            y = batch[\"mask\"].float().unsqueeze(1)\n",
    "\n",
    "            train_augmentations = K.AugmentationSequential(\n",
    "                K.RandomRotation(p=0.5, degrees=90),\n",
    "                K.RandomHorizontalFlip(p=0.5),\n",
    "                K.RandomVerticalFlip(p=0.5),\n",
    "                K.RandomCrop(self.patch_size),\n",
    "                K.RandomSharpness(p=0.5),\n",
    "                data_keys=[\"input\", \"mask\"],\n",
    "            )\n",
    "            x, y = train_augmentations(x, y)\n",
    "\n",
    "            # torchmetrics expects masks to be longs without a channel dimension\n",
    "            batch[\"image\"] = x\n",
    "            batch[\"mask\"] = y.squeeze(1).long()\n",
    "\n",
    "        return batch\n",
    "        \n",
    "    def preprocess(self, sample):\n",
    "        sample[\"image\"] = (sample[\"image\"]  / 255.0).float()\n",
    "        sample[\"image\"] = torch.flatten(sample[\"image\"], 0, 1)\n",
    "        sample[\"mask\"] = sample[\"mask\"].long()\n",
    "        return sample\n",
    "\n",
    "    def prepare_data(self):\n",
    "        LEVIRCDPlus(split=\"train\", **self.kwargs)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_transforms = Compose([self.preprocess])\n",
    "        test_transforms = Compose([self.preprocess])\n",
    "\n",
    "        train_dataset = LEVIRCDPlus(\n",
    "            split=\"train\", transforms=train_transforms, **self.kwargs\n",
    "        )\n",
    "\n",
    "        if self.val_split_pct > 0.0:\n",
    "            self.train_dataset, self.val_dataset, _ = dataset_split(\n",
    "                train_dataset, val_pct=self.val_split_pct, test_pct=0.0\n",
    "            )\n",
    "        else:\n",
    "            self.train_dataset = train_dataset\n",
    "            self.val_dataset = train_dataset\n",
    "\n",
    "        self.test_dataset = LEVIRCDPlus(\n",
    "            split=\"test\", transforms=test_transforms, **self.kwargs\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221e5db",
   "metadata": {},
   "source": [
    "## Setting up a training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a5ff80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.144319600Z",
     "start_time": "2024-02-06T22:03:52.101036100Z"
    }
   },
   "outputs": [],
   "source": [
    "datamodule = LEVIRCDPlusDataModule(\n",
    "    root=\"data/LEVIRCDPlus\",\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_dataloader_workers,\n",
    "    val_split_pct=val_split_pct,\n",
    "    patch_size=(patch_size, patch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b472f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:52.486458300Z",
     "start_time": "2024-02-06T22:03:52.106326400Z"
    }
   },
   "outputs": [],
   "source": [
    "task = CustomSemanticSegmentationTask(\n",
    "    model=\"unet\",\n",
    "    backbone=\"resnet18\",\n",
    "    weights=True,\n",
    "    in_channels=6,\n",
    "    num_classes=2,\n",
    "    loss=\"ce\",\n",
    "    ignore_index=None,\n",
    "    lr=learning_rate,\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=experiment_dir,\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00,\n",
    "    patience=10,\n",
    ")\n",
    "\n",
    "tb_logger = TensorBoardLogger(\n",
    "    save_dir=\"logs/\",\n",
    "    name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\documents\\roofsense\\venv\\lib\\site-packages (2.15.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (1.26.2)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (68.2.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\documents\\roofsense\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:55.620701800Z",
     "start_time": "2024-02-06T22:03:52.485458700Z"
    }
   },
   "id": "b3209bdc6c268ef2",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:55.664203900Z",
     "start_time": "2024-02-06T22:03:55.619360700Z"
    }
   },
   "id": "e54642fd",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94fe9c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T22:03:55.667201300Z",
     "start_time": "2024-02-06T22:03:55.640319200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 2456), started 0:21:58 ago. (Use '!kill 2456' to kill it.)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-a82796a84691f828\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-a82796a84691f828\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5259c",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-06T22:03:55.650200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | CrossEntropyLoss | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | Unet             | 14.3 M\n",
      "---------------------------------------------------\n",
      "14.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.3 M    Total params\n",
      "57.351    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5e3e5f4588c45d89bec49239b7b10ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Documents\\RoofSense\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    logger=[tb_logger],\n",
    "    default_root_dir=experiment_dir,\n",
    "    min_epochs=10,\n",
    "    max_epochs=200,\n",
    "    accelerator='gpu',\n",
    "    devices=[gpu_id]\n",
    ")\n",
    "\n",
    "_ = trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfacd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e4afe",
   "metadata": {},
   "source": [
    "## Custom test step to compute the precision, recall, and F1 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61db9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to load a trained task from a checkpoint file\n",
    "# task = CustomSemanticSegmentationTask.load_from_checkpoint(\"results/...\")\n",
    "# datamodule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = task.model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e545e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_trues = []\n",
    "for batch in tqdm(datamodule.test_dataloader()):\n",
    "    images = batch[\"image\"].to(device)\n",
    "    y_trues.append(batch[\"mask\"].numpy().ravel()[::500])\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(images).argmax(dim=1).cpu().numpy().ravel()[::500]\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y_preds = np.concatenate(y_preds)\n",
    "y_trues = np.concatenate(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_trues, y_preds)\n",
    "recall = recall_score(y_trues, y_preds)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
